{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf40bbf-1a1d-46fa-82ab-ad8cfff4b9fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def Interferogram_Plot(D, C, B, G, F, J, E, I, pixels, _):\n",
    "    \"\"\"\n",
    "    Generate an interferogram plot with the given parameters.\n",
    "    \n",
    "    Parameters same as MATLAB version:\n",
    "    D: Defocus\n",
    "    C: Tilt(x)\n",
    "    B: Tilt(y)\n",
    "    G: Spherical\n",
    "    F: Coma(y)\n",
    "    J: Coma(x)\n",
    "    E: Astig(y)\n",
    "    I: Astig(x)\n",
    "    pixels: Resolution (square)\n",
    "    _: Unused parameter (kept for compatibility)\n",
    "    \"\"\"\n",
    "    \n",
    "    respix = pixels\n",
    "    \n",
    "    WFE = np.zeros((respix, respix))\n",
    "    \n",
    "    x = np.linspace(-(respix/2 - 0.5)/(respix/2), (respix/2 - 0.5)/(respix/2), respix)\n",
    "    y = np.linspace(-(respix/2 - 0.5)/(respix/2), (respix/2 - 0.5)/(respix/2), respix)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    OPD = (B * X + C * Y + \n",
    "           D * (X**2 + Y**2) + \n",
    "           E * (X**2 + 3*Y**2) + \n",
    "           F * Y * (X**2 + Y**2) + \n",
    "           G * (X**2 + Y**2)**2 + \n",
    "           J * X * (X**2 + Y**2) + \n",
    "           I * (3*X**2 + Y**2))\n",
    "    \n",
    "    WFE = OPD\n",
    "    \n",
    "    phase = 1 - np.abs(0.5 - (WFE - np.floor(WFE)))/0.5\n",
    "    \n",
    "    grey_plot = Image.fromarray((phase * 255).astype(np.uint8))\n",
    "    \n",
    "    return grey_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a4538c-c9a1-4723-ac5f-a6ca544627e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "cap = 5\n",
    "num_images = 4000\n",
    "res = 224\n",
    "\n",
    "if not os.path.exists('training'):\n",
    "    os.makedirs('training')\n",
    "\n",
    "np.random.seed() \n",
    "\n",
    "for img in range(num_images):\n",
    "    params = np.round(np.random.uniform(-cap, cap, 8), 6)\n",
    "\n",
    "    image = Interferogram_Plot(params[0], params[1], params[2], params[3],\n",
    "                             params[4], params[5], params[6], params[7],\n",
    "                             res, None)\n",
    "    \n",
    "    base_filename = f'img_D{params[0]:.6f}_C{params[1]:.6f}_B{params[2]:.6f}_G{params[3]:.6f}_' \\\n",
    "                   f'F{params[4]:.6f}_J{params[5]:.6f}_E{params[6]:.6f}_I{params[7]:.6f}'\n",
    "    \n",
    "    base_filename = base_filename.replace('-', 'n').replace('.', 'p')\n",
    "    \n",
    "    write_file = os.path.join('training', f'{base_filename}.jpg')\n",
    "    image.save(write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f947f23-c218-4a37-aad8-70025c674db3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/csse463/202520/06/myenv/bin/python\n",
      "Number of files: 40\n",
      "Model saved as: models/trained_network.pth\n",
      "\n",
      "=== Testing Some Predictions ===\n",
      "\n",
      "Sample 1:\n",
      "Predicted: D=0.3538, C=0.1651, B=-0.0904, G=0.6991, F=-0.2561, J=-0.6439, E=0.9614, I=-0.1587\n",
      "Actual:    D=1.5358, C=3.5613, B=-4.7948, G=-1.7157, F=-4.9548, J=-3.5965, E=1.0944, I=-3.1230\n",
      "Abs Error: D=1.1820, C=3.3962, B=4.7044, G=2.4149, F=4.6987, J=2.9527, E=0.1330, I=2.9642\n",
      "\n",
      "Sample 2:\n",
      "Predicted: D=0.2499, C=0.1048, B=0.0824, G=0.5808, F=-0.2120, J=-0.4875, E=0.6757, I=-0.1483\n",
      "Actual:    D=3.7628, C=-4.2970, B=0.8222, G=-4.5054, F=-0.3217, J=1.6811, E=-3.3811, I=-1.9742\n",
      "Abs Error: D=3.5129, C=4.4018, B=0.7398, G=5.0862, F=0.1097, J=2.1686, E=4.0568, I=1.8259\n",
      "\n",
      "Sample 3:\n",
      "Predicted: D=0.1733, C=0.0604, B=0.0781, G=0.4662, F=-0.1367, J=-0.3778, E=0.5268, I=-0.1460\n",
      "Actual:    D=4.2930, C=-4.4883, B=-3.4058, G=4.5360, F=1.2139, J=-0.5252, E=4.0946, I=-1.0538\n",
      "Abs Error: D=4.1197, C=4.5487, B=3.4839, G=4.0698, F=1.3506, J=0.1474, E=3.5677, I=0.9078\n",
      "\n",
      "Sample 4:\n",
      "Predicted: D=0.3082, C=0.1230, B=0.0517, G=0.5738, F=-0.2228, J=-0.5006, E=0.7556, I=-0.1576\n",
      "Actual:    D=-4.8545, C=-3.4244, B=-3.5633, G=-4.3701, F=0.6173, J=-0.0734, E=1.2772, I=-1.4778\n",
      "Abs Error: D=5.1627, C=3.5474, B=3.6150, G=4.9439, F=0.8402, J=0.4273, E=0.5216, I=1.3202\n",
      "\n",
      "Sample 5:\n",
      "Predicted: D=0.4274, C=0.1548, B=-0.0421, G=0.8027, F=-0.3361, J=-0.7626, E=1.1661, I=-0.3134\n",
      "Actual:    D=1.6025, C=2.1885, B=3.2550, G=-4.7456, F=-2.0661, J=-1.0097, E=0.7497, I=1.5131\n",
      "Abs Error: D=1.1750, C=2.0337, B=3.2971, G=5.5483, F=1.7300, J=0.2471, E=0.4165, I=1.8265\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "class InterferogramDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Grayscale(1)\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        name = name.replace('n', '-').replace('p', '.')\n",
    "        parts = name.split('_')\n",
    "        params = np.zeros(8)\n",
    "        for i, part in enumerate(parts[1:9]):\n",
    "            params[i] = float(part[1:])\n",
    "            \n",
    "        return image, torch.FloatTensor(params)\n",
    "\n",
    "class InterferogramNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InterferogramNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 112 * 112, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def preprocess_image(filename):\n",
    "    image = Image.open(filename).convert('L')\n",
    "    image = np.array(image, dtype=np.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def output_function(epoch, iteration, train_loss, train_rmse, val_loss=None, val_rmse=None, \n",
    "                   time_since_start=0, learning_rate=0):\n",
    "    if iteration % 100 == 0:\n",
    "        print(f'\\n=== Training Progress at Iteration {iteration} ===')\n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'Training Loss: {train_loss:.6f}')\n",
    "        print(f'Training RMSE: {train_rmse:.6f}')\n",
    "        if val_loss is not None:\n",
    "            print(f'Validation Loss: {val_loss:.6f}')\n",
    "            print(f'Validation RMSE: {val_rmse:.6f}')\n",
    "        print(f'Time Since Start: {time_since_start/60:.2f} minutes')\n",
    "        print(f'Current Learning Rate: {learning_rate:.6f}')\n",
    "        print('===================================\\n')\n",
    "\n",
    "def main\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    file_paths = glob.glob(os.path.join('training', '*.jpg'))\n",
    "    num_files = len(file_paths)\n",
    "    print(f'Number of files: {num_files}')\n",
    "    \n",
    "    full_dataset = InterferogramDataset(file_paths)\n",
    "    \n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=14, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=14, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = InterferogramNet().to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    num_epochs = 5\n",
    "    iteration = 0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            rmse = torch.sqrt(loss)\n",
    "            iteration += 1\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                val_rmse = 0\n",
    "                with torch.no_grad():\n",
    "                    for val_images, val_targets in val_loader:\n",
    "                        val_images, val_targets = val_images.to(device), val_targets.to(device)\n",
    "                        val_outputs = model(val_images)\n",
    "                        val_batch_loss = criterion(val_outputs, val_targets)\n",
    "                        val_loss += val_batch_loss.item()\n",
    "                        val_rmse += torch.sqrt(val_batch_loss).item()\n",
    "                \n",
    "                val_loss /= len(val_loader)\n",
    "                val_rmse /= len(val_loader)\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= 1:\n",
    "                        print(\"Early stopping triggered\")\n",
    "                        break\n",
    "                \n",
    "                output_function(epoch, iteration, loss.item(), rmse.item(),\n",
    "                              val_loss, val_rmse, iteration * 0.1, optimizer.param_groups[0]['lr'])\n",
    "                \n",
    "                model.train()\n",
    "    \n",
    "    save_dir = 'models'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model_path = os.path.join(save_dir, 'trained_network.pth')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f'Model saved as: {model_path}')\n",
    "    \n",
    "    print('\\n=== Testing Some Predictions ===')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_images, actual_params = next(iter(val_loader))\n",
    "        test_images, actual_params = test_images.to(device), actual_params.to(device)\n",
    "        predictions = model(test_images)\n",
    "        \n",
    "        for i in range(min(5, predictions.size(0))):\n",
    "            print(f'\\nSample {i+1}:')\n",
    "            print(f'Predicted: D={predictions[i,0]:.4f}, C={predictions[i,1]:.4f}, '\n",
    "                  f'B={predictions[i,2]:.4f}, G={predictions[i,3]:.4f}, '\n",
    "                  f'F={predictions[i,4]:.4f}, J={predictions[i,5]:.4f}, '\n",
    "                  f'E={predictions[i,6]:.4f}, I={predictions[i,7]:.4f}')\n",
    "            print(f'Actual:    D={actual_params[i,0]:.4f}, C={actual_params[i,1]:.4f}, '\n",
    "                  f'B={actual_params[i,2]:.4f}, G={actual_params[i,3]:.4f}, '\n",
    "                  f'F={actual_params[i,4]:.4f}, J={actual_params[i,5]:.4f}, '\n",
    "                  f'E={actual_params[i,6]:.4f}, I={actual_params[i,7]:.4f}')\n",
    "            \n",
    "            errors = torch.abs(predictions[i] - actual_params[i])\n",
    "            print(f'Abs Error: D={errors[0]:.4f}, C={errors[1]:.4f}, '\n",
    "                  f'B={errors[2]:.4f}, G={errors[3]:.4f}, '\n",
    "                  f'F={errors[4]:.4f}, J={errors[5]:.4f}, '\n",
    "                  f'E={errors[6]:.4f}, I={errors[7]:.4f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d891fc-6daa-4b9f-b4a2-88f1921c6325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
