{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d148305c-9fb0-4206-be51-bf613b24a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:4\n",
      "Epoch [1/20] | Train Loss: 0.090618 | Val Loss: 0.008445\n",
      "Epoch [2/20] | Train Loss: 0.056166 | Val Loss: 0.004962\n",
      "Epoch [3/20] | Train Loss: 0.045306 | Val Loss: 0.003025\n",
      "Epoch [4/20] | Train Loss: 0.038787 | Val Loss: 0.002085\n",
      "Epoch [5/20] | Train Loss: 0.032296 | Val Loss: 0.001777\n",
      "Epoch [6/20] | Train Loss: 0.028893 | Val Loss: 0.001787\n",
      "Epoch [7/20] | Train Loss: 0.025621 | Val Loss: 0.001291\n",
      "Epoch [8/20] | Train Loss: 0.022975 | Val Loss: 0.001152\n",
      "Epoch [9/20] | Train Loss: 0.019948 | Val Loss: 0.000931\n",
      "Epoch [10/20] | Train Loss: 0.017492 | Val Loss: 0.000841\n",
      "Epoch [11/20] | Train Loss: 0.016149 | Val Loss: 0.000693\n",
      "Epoch [12/20] | Train Loss: 0.013857 | Val Loss: 0.000616\n",
      "Epoch [13/20] | Train Loss: 0.012671 | Val Loss: 0.000644\n",
      "Epoch [14/20] | Train Loss: 0.011375 | Val Loss: 0.000542\n",
      "Epoch [15/20] | Train Loss: 0.010749 | Val Loss: 0.000519\n",
      "Epoch [16/20] | Train Loss: 0.009380 | Val Loss: 0.000538\n",
      "Epoch [17/20] | Train Loss: 0.008294 | Val Loss: 0.000475\n",
      "Epoch [18/20] | Train Loss: 0.007626 | Val Loss: 0.000439\n",
      "Epoch [19/20] | Train Loss: 0.006886 | Val Loss: 0.000398\n",
      "Epoch [20/20] | Train Loss: 0.006361 | Val Loss: 0.000350\n",
      "Model saved as transfer_model.pth\n",
      "Evaluating model on validation set...\n",
      "\n",
      "Sample 1:\n",
      "Predicted: [ 0.02053889  0.11271998  0.08988129  0.10982405  0.07205125  0.00321625\n",
      "  0.1219701  -0.13103619]\n",
      "Actual:    [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Abs Error: [0.02053889 0.11271998 0.08988129 0.10982405 0.07205125 0.00321625\n",
      " 0.1219701  0.13103619]\n",
      "\n",
      "Sample 2:\n",
      "Predicted: [ 0.04058966 -0.06241258  0.01916997 -0.05277509  0.03150992  0.072884\n",
      " -0.14533766 -0.01646851]\n",
      "Actual:    [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Abs Error: [0.04058966 0.06241258 0.01916997 0.05277509 0.03150992 0.072884\n",
      " 0.14533766 0.01646851]\n",
      "\n",
      "Sample 3:\n",
      "Predicted: [-0.13336287  0.0331971   0.04968951  0.14760661  0.04291616  0.07277723\n",
      " -0.07679116  0.14222203]\n",
      "Actual:    [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Abs Error: [0.13336287 0.0331971  0.04968951 0.14760661 0.04291616 0.07277723\n",
      " 0.07679116 0.14222203]\n",
      "\n",
      "Sample 4:\n",
      "Predicted: [-0.16058439  0.01756694  0.13620538  0.14736208 -0.12341455  0.15494047\n",
      " -0.08037437  0.07443816]\n",
      "Actual:    [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Abs Error: [0.16058439 0.01756694 0.13620538 0.14736208 0.12341455 0.15494047\n",
      " 0.08037437 0.07443816]\n",
      "\n",
      "Sample 5:\n",
      "Predicted: [-0.05539041 -0.10873191 -0.09610467  0.06308772 -0.06061818  0.04476804\n",
      "  0.06268442 -0.08133744]\n",
      "Actual:    [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Abs Error: [0.05539041 0.10873191 0.09610467 0.06308772 0.06061818 0.04476804\n",
      " 0.06268442 0.08133744]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device(\"cuda:4\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the Autoencoder Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# Define the Transfer Learning Model\n",
    "class TransferModel(nn.Module):\n",
    "    def __init__(self, encoder, classifier):\n",
    "        super(TransferModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten before classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Load Pretrained Encoder\n",
    "encoder = Encoder()\n",
    "encoder.load_state_dict(torch.load(\"autoencoder.pth\", map_location=device), strict=False)\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# Freeze Encoder Layers\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define the Classifier from the CNN Model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 28 * 28, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 8)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Create Model\n",
    "classifier = Classifier().to(device)\n",
    "model = TransferModel(encoder, classifier).to(device)\n",
    "\n",
    "# Define Training Parameters\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, targets in train_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss/len(train_loader):.6f} | Val Loss: {val_loss/len(val_loader):.6f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), 'transfer_model.pth')\n",
    "    print(\"Model saved as transfer_model.pth\")\n",
    "\n",
    "# Data Loader Function\n",
    "def get_data_loaders(root_folder, batch_size=40, num_workers=12):\n",
    "    file_paths = glob.glob(os.path.join(root_folder, '*.jpg'))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    class Dataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, file_paths, transform):\n",
    "            self.file_paths = file_paths\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            image = Image.open(self.file_paths[idx])\n",
    "            image = self.transform(image)\n",
    "            return image, torch.zeros(8)  # Placeholder target\n",
    "    \n",
    "    dataset = Dataset(file_paths, transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    print(\"Evaluating model on validation set...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, actual_params in val_loader:\n",
    "            images, actual_params = images.to(device), actual_params.to(device)\n",
    "            predictions = model(images)\n",
    "            break  # Display only the first batch\n",
    "\n",
    "    # Denormalize predictions and actual values\n",
    "    predictions = predictions.cpu().numpy() * 5 # Scale back to [-5, 5]\n",
    "    actual_params = actual_params.cpu().numpy() * 5  # Scale back to [-5, 5]\n",
    "\n",
    "    for i in range(min(5, predictions.shape[0])):\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Predicted: {predictions[i]}\")\n",
    "        print(f\"Actual:    {actual_params[i]}\")\n",
    "        print(f\"Abs Error: {np.abs(predictions[i] - actual_params[i])}\")\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == '__main__':\n",
    "    train_loader, val_loader = get_data_loaders('training', batch_size=40, num_workers=12)\n",
    "    train_model(model, train_loader, val_loader, num_epochs=20)\n",
    "    evaluate_model(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd99a468-7524-4def-893c-93d7dfca4b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/20] | Train Loss: 8.392342 | Val Loss: 8.313062\n",
      "Epoch [2/20] | Train Loss: 8.354016 | Val Loss: 8.313567\n",
      "Epoch [3/20] | Train Loss: 8.347391 | Val Loss: 8.314226\n",
      "Epoch [4/20] | Train Loss: 8.342511 | Val Loss: 8.312906\n",
      "Epoch [5/20] | Train Loss: 8.339682 | Val Loss: 8.311634\n",
      "Epoch [6/20] | Train Loss: 8.336941 | Val Loss: 8.311463\n",
      "Epoch [7/20] | Train Loss: 8.336533 | Val Loss: 8.310827\n",
      "Epoch [8/20] | Train Loss: 8.335437 | Val Loss: 8.311628\n",
      "Epoch [9/20] | Train Loss: 8.334539 | Val Loss: 8.310966\n",
      "Epoch [10/20] | Train Loss: 8.334490 | Val Loss: 8.309077\n",
      "Epoch [11/20] | Train Loss: 8.333390 | Val Loss: 8.310103\n",
      "Epoch [12/20] | Train Loss: 8.333456 | Val Loss: 8.310214\n",
      "Epoch [13/20] | Train Loss: 8.332027 | Val Loss: 8.309866\n",
      "Epoch [14/20] | Train Loss: 8.332919 | Val Loss: 8.309618\n",
      "Epoch [15/20] | Train Loss: 8.332160 | Val Loss: 8.309018\n",
      "Epoch [16/20] | Train Loss: 8.333633 | Val Loss: 8.308921\n",
      "Epoch [17/20] | Train Loss: 8.331893 | Val Loss: 8.310053\n",
      "Epoch [18/20] | Train Loss: 8.333305 | Val Loss: 8.309403\n",
      "Epoch [19/20] | Train Loss: 8.332682 | Val Loss: 8.309394\n",
      "Epoch [20/20] | Train Loss: 8.332170 | Val Loss: 8.308734\n",
      "Model saved as transfer_model.pth\n",
      "Evaluation Loss: 8.308734\n",
      "\n",
      "Sample 1:\n",
      "Predicted: [-0.01432773  0.00875246 -0.03962421 -0.019959   -0.00507158  0.03263142\n",
      " -0.00828417 -0.00686782]\n",
      "Actual:    [ 2.368424 -0.322694  0.423589  2.384404  3.00977  -3.139944 -0.786712\n",
      " -1.744975]\n",
      "Abs Error: [2.3827517  0.33144647 0.4632132  2.404363   3.0148416  3.1725755\n",
      " 0.77842784 1.7381072 ]\n",
      "\n",
      "Sample 2:\n",
      "Predicted: [ 0.00678797 -0.0037992   0.01031065 -0.00662457  0.01236614  0.03538647\n",
      "  0.00980034 -0.06214331]\n",
      "Actual:    [-4.554007  0.257897  4.265564 -1.563534 -2.204139  4.332105  2.342633\n",
      " -4.012137]\n",
      "Abs Error: [4.560795  0.2616962 4.2552533 1.5569094 2.216505  4.2967186 2.3328326\n",
      " 3.9499936]\n",
      "\n",
      "Sample 3:\n",
      "Predicted: [ 0.00264343 -0.01155462 -0.03101172  0.0050689   0.0102692  -0.00444786\n",
      " -0.02858662 -0.02547188]\n",
      "Actual:    [-4.891039 -0.852318  3.129235 -0.193781  1.709651  2.032996  0.460509\n",
      "  2.912267]\n",
      "Abs Error: [4.8936825  0.8407634  3.1602468  0.1988499  1.6993818  2.0374439\n",
      " 0.48909563 2.937739  ]\n",
      "\n",
      "Sample 4:\n",
      "Predicted: [ 0.0219378   0.04641398 -0.04570337  0.01002268 -0.08006927  0.00764713\n",
      " -0.07758201  0.06439494]\n",
      "Actual:    [-1.119871 -4.143288 -3.463779  0.065004  3.994017  3.880126  0.410554\n",
      "  3.757305]\n",
      "Abs Error: [1.1418089  4.189702   3.4180756  0.05498132 4.074086   3.872479\n",
      " 0.488136   3.69291   ]\n",
      "\n",
      "Sample 5:\n",
      "Predicted: [ 0.01209482  0.01111555  0.01518594 -0.00786095  0.009779    0.04727378\n",
      "  0.03479515 -0.0773585 ]\n",
      "Actual:    [-2.339302 -0.299839  2.471704 -2.198785 -1.118738  2.6016    1.211008\n",
      " -3.872164]\n",
      "Abs Error: [2.3513968  0.31095454 2.4565182  2.1909242  1.128517   2.554326\n",
      " 1.1762128  3.7948055 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the Autoencoder Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# Define the Transfer Learning Model\n",
    "class TransferModel(nn.Module):\n",
    "    def __init__(self, encoder, classifier):\n",
    "        super(TransferModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten before classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Load Pretrained Encoder\n",
    "encoder = Encoder()\n",
    "encoder.load_state_dict(torch.load(\"autoencoder.pth\", map_location=device), strict=False)\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# Freeze Encoder Layers\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define the Classifier from the CNN Model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 28 * 28, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 8)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Create Model\n",
    "classifier = Classifier().to(device)\n",
    "model = TransferModel(encoder, classifier).to(device)\n",
    "\n",
    "# Define Training Parameters\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, targets in train_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss/len(train_loader):.6f} | Val Loss: {val_loss/len(val_loader):.6f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), 'transfer_model.pth')\n",
    "    print(\"Model saved as transfer_model.pth\")\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    print(f\"Evaluation Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    # Display sample predictions\n",
    "    sample_images, sample_targets = next(iter(val_loader))\n",
    "    sample_images, sample_targets = sample_images.to(device), sample_targets.to(device)\n",
    "    sample_outputs = model(sample_images).detach()\n",
    "    \n",
    "    for i in range(min(5, sample_outputs.size(0))):\n",
    "        predicted = sample_outputs[i].cpu().numpy()\n",
    "        actual = sample_targets[i].cpu().numpy()\n",
    "        abs_error = abs(predicted - actual)\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Predicted: {predicted}\")\n",
    "        print(f\"Actual:    {actual}\")\n",
    "        print(f\"Abs Error: {abs_error}\")\n",
    "\n",
    "# Data Loader Function\n",
    "def get_data_loaders(root_folder, batch_size=40, num_workers=12):\n",
    "    file_paths = glob.glob(os.path.join(root_folder, '*.jpg'))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    class Dataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, file_paths, transform):\n",
    "            self.file_paths = file_paths\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            image = Image.open(self.file_paths[idx])\n",
    "            image = self.transform(image)\n",
    "            \n",
    "            # Extract coefficients from filename\n",
    "            name = os.path.splitext(os.path.basename(self.file_paths[idx]))[0]\n",
    "            name = name.replace('n', '-').replace('p', '.')\n",
    "            parts = re.findall(r'[-+]?[0-9]*\\.?[0-9]+', name)\n",
    "            params = np.array([float(p) for p in parts[:8]])  # Extract first 8 coefficients\n",
    "            params = torch.FloatTensor(params)\n",
    "            \n",
    "            return image, params\n",
    "    \n",
    "    dataset = Dataset(file_paths, transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == '__main__':\n",
    "    train_loader, val_loader = get_data_loaders('training2', batch_size=40, num_workers=12)\n",
    "    train_model(model, train_loader, val_loader, num_epochs=20)\n",
    "    evaluate_model(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f54bcd-d5cb-4f6e-9a1b-632a1541a534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenvAN)",
   "language": "python",
   "name": "myenvan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
